{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask Detector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUxxgF4s9zNFbxr8g3yyKz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SuyashSonawane/Mask-Detector/blob/master/Mask_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQnM0T819oam",
        "colab_type": "text"
      },
      "source": [
        "## Step1\n",
        ">**Downloading Data from Kaggel**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE0IGnU7TaDK",
        "colab_type": "text"
      },
      "source": [
        "This installs `kaggel cli` tool that will help us to download dataset directly from the command line"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSi_zXIL88ub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCQLTuYmTy76",
        "colab_type": "text"
      },
      "source": [
        "This is Google Colab specific command, from here we can upload the `kaggle.json` file, which holds our API credentials."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p1Feqhz9Oaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSuSpRwWUWMP",
        "colab_type": "text"
      },
      "source": [
        "By running the below code, a zip will get downloaded in the current directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1GDFhKE9jTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d ahmetfurkandemr/mask-datasets-v1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k0T2bdt_bnE",
        "colab_type": "text"
      },
      "source": [
        "Unziping Data in the database folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g04PHDu9_k1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = \"mask-datasets-v1.zip\"\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('./database')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L51EsAgUUrE5",
        "colab_type": "text"
      },
      "source": [
        "## Step2\n",
        ">**Preparing the data**\n",
        "\n",
        "Getting the directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ7qDAb3_P6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = 'database/Mask_Datasets/Train'\n",
        "validation_dir = 'database/Mask_Datasets/Validation'\n",
        "\n",
        "train_mask_dir = os.path.join(train_dir, 'Mask')\n",
        "train_nomask_dir = os.path.join(train_dir, 'No_mask')\n",
        "validation_mask_dir = os.path.join(validation_dir, 'Mask')\n",
        "validation_nomask_dir = os.path.join(validation_dir, 'No_mask')\n",
        "\n",
        "train_mask_fnames =os.listdir(train_mask_dir)\n",
        "train_nomask_fnames =os.listdir(train_nomask_dir)\n",
        "validation_mask_fnames = os.listdir(validation_mask_dir)\n",
        "validation_nomask_fnames = os.listdir(validation_nomask_dir)\n",
        "\n",
        "print(len(train_mask_fnames))\n",
        "print(len(train_nomask_fnames))\n",
        "print(len(validation_mask_fnames))\n",
        "print(len(validation_nomask_fnames))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pzNnrA1VS53",
        "colab_type": "text"
      },
      "source": [
        "## Step3\n",
        "> **Now we will start with the Neural Network Tasks**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2QQByhWVg_u",
        "colab_type": "text"
      },
      "source": [
        "Due to the small dataset, we will do some image augmentation with TensorFlow's `Image Data Generator`.\n",
        "\n",
        "We will normalize the images by dividing them by `255`.\n",
        "\n",
        "We have `10` as batch size and as the images are of different sizes we set the target size as `(28,28)`\n",
        "\n",
        "As we have a binary classification problem, we have class_mode as `binary`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScWa1qyYApY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 10,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (28, 28))     \n",
        "\n",
        "\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 10,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (28, 28))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUbSV8YjV1WI",
        "colab_type": "text"
      },
      "source": [
        "Now we will structure our Neural Network with TensorFlow's Keras Layers API,\n",
        "we will define 3 Convolutional Layers each with Max Pooling of shape `(2,2)`.\n",
        "\n",
        "Then we will compile the model with loss function as `Binary Crossentropy` as we have to do a binary classification , we will use the `RMSprop` Optimizer with learning rate of `10^-4` and accuracy as metrics.\n",
        "\n",
        "Finally we will print out the model summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a36thdKxAzBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8C2TWqnYJNA",
        "colab_type": "text"
      },
      "source": [
        "Below is a callback function which can be used to stop the training once we have the accuracy over `97%`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIDSFFJRBeXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.97):\n",
        "      print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO-zqDFMYe_t",
        "colab_type": "text"
      },
      "source": [
        "Now we will train the model with 100 epochs and will save all the training history in the history object "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1E68wE5Bq2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback=myCallback()\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=75,  \n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,validation_steps=35\n",
        "      )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JrVbbqYZUKt",
        "colab_type": "text"
      },
      "source": [
        "## Step4\n",
        ">**Visulazing results**\n",
        "\n",
        "Now our model is trained and we will picture out the training and validation, accuracy and loss using `Matplotlib` library in python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlixwCxDB2DX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86-6si1lffAb",
        "colab_type": "text"
      },
      "source": [
        "Now we can test our model by uploading pics to the Colab Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMZDtr6NKlJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        " \n",
        "  # predicting images\n",
        "for fn in os.listdir(\"/content\"):\n",
        "  if(fn.endswith(('.png','.jpg'))):\n",
        "    path = fn\n",
        "    img = image.load_img(path, target_size=(28, 28))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    images = np.vstack([x])\n",
        "    classes = model.predict(images, batch_size=10)\n",
        "    print(fn)\n",
        "    print(classes)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}